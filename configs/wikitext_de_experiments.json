{
    "model_name_or_path": "models/pythia-410m-clp-german",
    "output_dir": "results/wikitext_de_experiments",
    "validation_split_percentage": 5,
    "dataset_name": "PatrickHaller/wikitext-18-de",
    "per_device_train_batch_size": 8,
    "per_device_eval_batch_size": 8,
    "full_training_learning_rate": 3e-4,
    "min_lr": 3e-5,
    "weight_decay": 0.1,
    "beta1": 0.9,
    "beta2": 0.95,
    "grad_clip": 1.0,
    "gradient_accumulation_steps": 2,
    "num_train_epochs": 1,
    "block_size": 512,
    "preprocessing_num_workers": 1,
    "seed": 42,
    "checkpointing_steps": "epoch",
    "eval_steps": "20",
    "eval_iters": 50
}