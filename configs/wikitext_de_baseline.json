{
    "model_name_or_path": "models/pythia-410m-clp-german",
    "output_dir": "results/wikitext_de_baseline",
    "validation_split_percentage": 5,
    "dataset_name": "PatrickHaller/wikitext-18-de",
    "per_device_train_batch_size": 8,
    "per_device_eval_batch_size": 8,
    "lr_scheduler_type": "cosine_schedule_with_warmup",
    "learning_rate": 3e-04,
    "full_training_learning_rate": 3e-04,
    "min_lr": 3e-05,
    "weight_decay": 0.1,
    "beta1": 0.9,
    "beta2": 0.95,
    "grad_clip": 1.0,
    "gradient_accumulation_steps": 4,
    "embedding_tuning_percentage": 0,
    "warmup_percentage": 1,
    "num_train_epochs": 1,
    "block_size": 512,
    "preprocessing_num_workers": 1,
    "seed": 42,
    "eval_steps": "10",
    "eval_iters": 50,
    "calculate_warmup_based_on_num_train_steps": true
}